<!doctype html>
<html lang=en dir=auto>

<head>
    <meta charset=utf-8>
    <meta http-equiv=x-ua-compatible content="IE=edge">
    <meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
    <meta name=robots content="index, follow">
    <title>Reptile Learning | zhang远</title>
    <meta name=keywords content="python">
    <meta name=description
        content="urllib库（request更方便，在于不用再去构建一个get或者post请求）
urllib库包含以下几个模块（模块里面是函数）： urllib.request - 打开和读取 URL。 urllib.error - 包含 urllib.request 抛出的异常。 urllib.parse - 解析 URL。 # urllib.robotparser - 解析 robots.txt 文件。 拓: getcode() 函数获取'网页状态码'，返回 200 说明网页正常，返回 404 说明网页不存在 get_text()获取除标签以外的'文本内容'。 .attrs获取'标签对象的属性'，返回一个字典。 body = '\n'.join([line.text for line in lines]) # 有意思的一种换行循环加入列表。 title = bs.find('h1').text # text什么意思,去除标签获取文本。 用类来设置属性。 zip()函数：for i n in zip(is,ns):['用以设置一个双循环'] str.strip([chars]); 参数chars -- 移除字符串'头尾'指定的字符序列。 1.'urllib.request模块' urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) url：url 地址。 data：发送到服务器的其他数据对象，默认为 None。 timeout：设置访问超时时间。 cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。 cadefault：已经被弃用。 context：ssl.">
    <meta name=author content="Me">
    <link rel=canonical href=/posts/reptilebase />
    <link crossorigin=anonymous
        href=/assets/css/stylesheet.526a38c1d1593cf713bc007a19fc7b2f5a9f37ff520f0dbfe894119bd87f754b.css
        integrity="sha256-Umo4wdFZPPcTvAB6Gfx7L1qfN/9SDw2/6JQRm9h/dUs=" rel="preload stylesheet" as=style>
    <script defer crossorigin=anonymous
        src=/assets/js/highlight.acb54fd32bbc1982428b8850317e45d076b95012730a5936667e6bc21777692a.js
        integrity="sha256-rLVP0yu8GYJCi4hQMX5F0Ha5UBJzClk2Zn5rwhd3aSo=" onload=hljs.initHighlightingOnLoad()></script>
    <link rel=icon href=favicon.ico>
    <link rel=icon type=image/png sizes=16x16 href=favicon-16x16.png>
    <link rel=icon type=image/png sizes=32x32 href=favicon-32x32.png>
    <link rel=apple-touch-icon href=apple-touch-icon.png>
    <link rel=mask-icon href=safari-pinned-tab.svg>
    <meta name=theme-color content="#2e2e33">
    <meta name=msapplication-TileColor content="#2e2e33"><noscript>
        <style>
            #theme-toggle,
            .top-link {
                display: none;
            }
        </style>
        <style>
            @media (prefers-color-scheme: dark) {
                :root {
                    --theme: rgb(29, 30, 32);
                    --entry: rgb(46, 46, 51);
                    --primary: rgb(218, 218, 219);
                    --secondary: rgb(155, 156, 157);
                    --tertiary: rgb(65, 66, 68);
                    --content: rgb(196, 196, 197);
                    --hljs-bg: rgb(46, 46, 51);
                    --code-bg: rgb(55, 56, 62);
                    --border: rgb(51, 51, 51);
                }

                .list {
                    background: var(--theme);
                }

                .list:not(.dark)::-webkit-scrollbar-track {
                    background: 0 0;
                }

                .list:not(.dark)::-webkit-scrollbar-thumb {
                    border-color: var(--theme);
                }
            }
        </style>
    </noscript>
    <meta property="og:title" content="Reptile Learning">
    <meta property="og:description"
        content="urllib库（request更方便，在于不用再去构建一个get或者post请求）
urllib库包含以下几个模块（模块里面是函数）： urllib.request - 打开和读取 URL。 urllib.error - 包含 urllib.request 抛出的异常。 urllib.parse - 解析 URL。 # urllib.robotparser - 解析 robots.txt 文件。 拓: getcode() 函数获取'网页状态码'，返回 200 说明网页正常，返回 404 说明网页不存在 get_text()获取除标签以外的'文本内容'。 .attrs获取'标签对象的属性'，返回一个字典。 body = '\n'.join([line.text for line in lines]) # 有意思的一种换行循环加入列表。 title = bs.find('h1').text # text什么意思,去除标签获取文本。 用类来设置属性。 zip()函数：for i n in zip(is,ns):['用以设置一个双循环'] str.strip([chars]); 参数chars -- 移除字符串'头尾'指定的字符序列。 1.'urllib.request模块' urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) url：url 地址。 data：发送到服务器的其他数据对象，默认为 None。 timeout：设置访问超时时间。 cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。 cadefault：已经被弃用。 context：ssl.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="/posts/reptilebase/">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-09-24T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-09-24T00:00:00+00:00">
    <meta property="og:site_name" content="ExampleSite">
    <meta name=twitter:card content="summary">
    <meta name=twitter:title content="Reptile Learning">
    <meta name=twitter:description
        content="urllib库（request更方便，在于不用再去构建一个get或者post请求）
urllib库包含以下几个模块（模块里面是函数）： urllib.request - 打开和读取 URL。 urllib.error - 包含 urllib.request 抛出的异常。 urllib.parse - 解析 URL。 # urllib.robotparser - 解析 robots.txt 文件。 拓: getcode() 函数获取'网页状态码'，返回 200 说明网页正常，返回 404 说明网页不存在 get_text()获取除标签以外的'文本内容'。 .attrs获取'标签对象的属性'，返回一个字典。 body = '\n'.join([line.text for line in lines]) # 有意思的一种换行循环加入列表。 title = bs.find('h1').text # text什么意思,去除标签获取文本。 用类来设置属性。 zip()函数：for i n in zip(is,ns):['用以设置一个双循环'] str.strip([chars]); 参数chars -- 移除字符串'头尾'指定的字符序列。 1.'urllib.request模块' urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) url：url 地址。 data：发送到服务器的其他数据对象，默认为 None。 timeout：设置访问超时时间。 cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。 cadefault：已经被弃用。 context：ssl.">
    <script
        type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"/posts/"},{"@type":"ListItem","position":3,"name":"Reptile Learning","item":"/posts/reptilebase/"}]}</script>
    <script
        type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Reptile Learning","name":"Reptile Learning","description":"urllib库（request更方便，在于不用再去构建一个get或者post请求）\nurllib库包含以下几个模块（模块里面是函数）： urllib.request - 打开和读取 URL。 urllib.error - 包含 urllib.request 抛出的异常。 urllib.parse - 解析 URL。 # urllib.robotparser - 解析 robots.txt 文件。 拓: getcode() 函数获取\u0026#39;网页状态码\u0026#39;，返回 200 说明网页正常，返回 404 说明网页不存在 get_text()获取除标签以外的\u0026#39;文本内容\u0026#39;。 .attrs获取\u0026#39;标签对象的属性\u0026#39;，返回一个字典。 body = \u0026#39;\\n\u0026#39;.join([line.text for line in lines]) # 有意思的一种换行循环加入列表。 title = bs.find(\u0026#39;h1\u0026#39;).text # text什么意思,去除标签获取文本。 用类来设置属性。 zip()函数：for i n in zip(is,ns):[\u0026#39;用以设置一个双循环\u0026#39;] str.strip([chars]); 参数chars -- 移除字符串\u0026#39;头尾\u0026#39;指定的字符序列。 1.\u0026#39;urllib.request模块\u0026#39; urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) url：url 地址。 data：发送到服务器的其他数据对象，默认为 None。 timeout：设置访问超时时间。 cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。 cadefault：已经被弃用。 context：ssl.","keywords":["python"],"articleBody":"urllib库（request更方便，在于不用再去构建一个get或者post请求）\nurllib库包含以下几个模块（模块里面是函数）： urllib.request - 打开和读取 URL。 urllib.error - 包含 urllib.request 抛出的异常。 urllib.parse - 解析 URL。 # urllib.robotparser - 解析 robots.txt 文件。 拓: getcode() 函数获取'网页状态码'，返回 200 说明网页正常，返回 404 说明网页不存在 get_text()获取除标签以外的'文本内容'。 .attrs获取'标签对象的属性'，返回一个字典。 body = '\\n'.join([line.text for line in lines]) # 有意思的一种换行循环加入列表。 title = bs.find('h1').text # text什么意思,去除标签获取文本。 用类来设置属性。 zip()函数：for i n in zip(is,ns):['用以设置一个双循环'] str.strip([chars]); 参数chars -- 移除字符串'头尾'指定的字符序列。 1.'urllib.request模块' urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) url：url 地址。 data：发送到服务器的其他数据对象，默认为 None。 timeout：设置访问超时时间。 cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。 cadefault：已经被弃用。 context：ssl.SSLContext类型，用来指定 SSL 设置。 urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None) url：url 地址。 data：发送到服务器的其他数据对象，默认为 None。 # headers：HTTP 请求的头部信息，字典格式。 origin_req_host：请求的主机地址，IP 或域名。 unverifiable：很少用整个参数，用于设置网页是否需要验证，默认是Fals e。。 # method：请求方法， 如 GET、POST、DELETE、PUT等。 2.'urllib.error'模块 urllib.error 模块为 urllib.request 所引发的异常定义了异常类，基础异常类是 URLError。 urllib.error 包含了两个方法，URLError 和 HTTPError。 URLError 是 OSError 的一个子类，用于处理程序在遇到问题时会引发此异常（或其派生的异常），包含的属性 reason 为引发异常的原因。 HTTPError 是 URLError 的一个子类，用于处理特殊 HTTP 错误例如作为认证请求的时候，包含的属性 code 为 HTTP 的状态码， reason 为引发异常的原因，headers 为导致 HTTPError 的特定 HTTP 请求的 HTTP 响应头 BeautifulSoup\nbs = BeautifulSoup(html.read(), 'html.parser') # 'html.parser是python3中的解析器,lxml解析器需要特定安装,还有html5lib解析器。\t'特点就是可以转换成一个对象' print(bs.body.h1) # 返回一个网页标题。 几种异常的获取和分类\n1、网页在服务器上不存在或者获取网页时出现错误（HTTP异常） 2、服务器不存在（URL异常） 3.AttributeError：这个错误就是说python找不到对应的对象的属性（一般是没有标签） from urllib.request import urlopen from bs4 import BeautifulSoup from urllib.error import URLError def gettiller(url): try: html = urlopen(url) except URLError: return None # except执行后就不会执行后面的代码 try: bs = BeautifulSoup(html.read(), 'html.parser') title = bs.body.h1 except AttributeError as e: # 几种错误的分类。 return None return title title = gettiller('http://www.pythonscraping.com/pages/page1.html') if title is None: print('无法找到页面') else: print(title) HTML解析\nBeautifulsoup库里面的四个对象： 1.BeautifulSoup对象获取整个文档 2.标签Tag对象函数find与函数find_all获取 3.NavigableString对象表示标签里面的文字。（需要了解函数） 4.comment对象获取注释（需要了解函数） 标签对象.get_text()会清除HTML文档中的所有标签，返回字符串 # find（）与fand_all（）函数： find(标签，标签属性（{class:''})，递归布尔变量，text='匹配文本内容'，keuwords关键字参数） find_all() [关键字keywords:'id是一种HTML属性'（都可以直接用claas的字典属性获取），class_='green'直接获取具有green颜色属性的标签] 导航树： 1.子标签和父标签以及后代标签（区别） .descendants后代标签 .children子标签 2.处理兄弟标签 .next_siblings获取所有'兄弟标签' .previous_siblings当你知道兄弟标签的最后一个标签后可获取前面的'所有标签'（当然得是复数形式） 3.处理父标签 .parent .parents 例子：print(bs.find('img', {'src': '../img/gifts/img1.jpg'}).parent.previous_sibling.get_text()) 4.正则表达式和BeautifulSoup from urllib.request import urlopen from bs4 import BeautifulSoup import re html = urlopen('https://www.pythonscraping.com/pages/page3.html') bs = BeautifulSoup(html.read(), 'html.parser') images = bs.find_all('img', dict(src=re.compile('\\.\\./img/gifts/img.*\\.jpg'))) for image in images: print(image.attrs['src']) # 可以获取图片的地址。 5.Lambda表达式 #不太会 编写网络爬虫\n1.网页跳转（'急需改进'） from urllib.request import urlopen from bs4 import BeautifulSoup import random import datetime random.seed(datetime.datetime.now()) # 随机数 def getLinks(art): html = urlopen('https://en.wikipedia.beta.wmflabs.org{}'.format(art)) bs = BeautifulSoup(html, 'html.parser') return bs.find('div', {'id': 'mw-content-text'}).find_all('a', {'class': 'new'}) # 不可以用class，太死板。 links = getLinks('/wiki/Kyberpunk') while len(links) \u003e 0: newArticle = links[random.randint(0, len(links) - 1)].attrs['href'] print(newArticle) links = getLinks(newArticle) 2.随机数种子 random.seed(datetime.datetime.now()) # 不知道何用？ 3.爬取网站('还是不知道错在哪？') from urllib.request import urlopen from bs4 import BeautifulSoup import re page = set() def getLinks(art): global page html = urlopen('https://en.wikipedia.beta.wmflabs.org{}'.format(art)) bs = BeautifulSoup(html.read(), 'html.parser') for link in bs.find_all('a', href=re.compile('^(/wiki/)')): if 'href' in link.attrs: if link.attrs['href'] not in page: newPage = link.attrs['href'] print(newPage) page.add(newPage) getLinks(newPage) getLinks('') 3.请求头的设置 import urllib.request '要先导入urllib.request模块' header = { 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36 Edg/96.0.1054.62'} resquest = urllib.request.Request('https://en.wikipedia.beta.wmflabs.org' ,headers=header) html = urlopen(resquest) bs = BeautifulSoup(html.read(), 'html.parser') 收集网站数据\n1.from urllib.request import urlopen from bs4 import BeautifulSoup import re pages = set() def getLink(art): global pages html = urlopen('https://en.wikipedia.beta.wmflabs.org{}'.format(art)) bs = BeautifulSoup(html.read(), 'html.parser') try: print(bs.h1.get_text())\t# 这种多行检测容易失去一些数据。 print(bs.find(id='mw-content-text').find_all('p')) print(bs.find(id='ca-edit').find('span').find('a').attrs['href']) except AttributeError:\t# 即使报错也也会进行下一步。 print('页面缺少了一些属性.') for link in bs.find_all('a', href=re.compile('^(/wiki/)')): if 'href' in link.attrs: if link.attrs['href'] not in pages: newpPage = link.attrs['href'] print('-' * 20) print(newpPage) pages.add(newpPage) getLink(newpPage) getLink('') 难点：各种标签的规律（花时间去了解一下标签的的东西）。 2.'startswith()'方法用于检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。 语法 startswith()方法语法： str.startswith(str, beg=0,end=len(string)); 参数 str -- 检测的字符串。 strbeg -- 可选参数用于设置字符串检测的起始位置。 strend -- 可选参数用于设置字符串检测的结束位置。 返回值 如果检测到字符串则返回True，否则返回False。 在互联网上抓取\nfrom urllib.request import urlopen from urllib.parse import urlparse\t# 用于解析 from bs4 import BeautifulSoup import re import datetime import random pages = set() random.seed(datetime.datetime.now()) def getInUrl(bs, includeUrl): # 搜集内链 includeUrl = '{}://{}'.format(urlparse(includeUrl).scheme, urlparse(includeUrl).netloc) inLinks = [] for link in bs.find_all('a', href=re.compile('^(/|.*' + includeUrl + ')')): if link.attrs['href'] is not None: if link.attrs['href'] not in inLinks: if link.attrs['href'].startswith('/'): inLinks.append(includeUrl + link.attrs['href']) else: inLinks.append(link.attrs['href']) return inLinks def getExitUrl(bs, exUrl):\t# 搜集外链 exLinks = [] for link in bs.find_all('a', href=re.compile('^(http|www)((?!' + exUrl + ').)*$')): # 正则表达式。 if link.attrs['href'] is not None: if link.attrs['href'] not in exLinks: exLinks.append(link.attrs['href']) return exLinks def getRandomExternalLinks(startingPage): # 随机获取外部链接。（开始页面) html = urlopen(startingPage) bs = BeautifulSoup(html.read(), 'html.parser') exLinks = getExitUrl(bs, urlparse(startingPage).netloc) # 获取域名,获取外链。 if len(exLinks) == 0: print('不存在外部链接（一般不可能)') domain = '{}://{}'.format(urlparse(startingPage).scheme, urlparse(startingPage).netloc) internalLink = getInUrl(bs, domain) # 就去寻求另一个内链。 return getRandomExternalLinks(internalLink[random.randint(0, len(internalLink) - 1)]) else: return exLinks[random.randint(0, len(exLinks))] # 随机返回一个外链 def followExternalOnly(startingSite):\t# 实现网站跳转。 exLink = getRandomExternalLinks(startingSite) print('随机获取的外部链接是{}'.format(exLink)) followExternalOnly(exLink) followExternalOnly('http://oreilly.com') 1.'urlparse()'函数可以将 URL 解析成 ParseResult对象。对象中包含了六个元素，分别为： from urllib.parse import urlparse 协议（.scheme） 域名（.netloc） 路径（.path） 路径参数（.params） 查询参数（.query） 片段（.fragment） 2.'select()'函数[相当于fand_all的用法] 我们在写 CSS 时，标签名不加任何修饰，类名（class=\"className\"引号内即为类名）前加点，id名（id=\"idName\"引号前即为id名）前加 #，在这里我们也可以利用类似的方法来筛选元素，用到的方法是 bs.select()，返回类型是 list 3.以下是request.exceptions下的各种异常错误： 'RequestException' 4.Python replace() 方法用于把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。 语法： str.replace(old, new[, max]) 5.os.path.exists()就是判断括号里的文件是否存在的意思【返回布尔值】 os.makedirs递归创建目录（无返回值） 6.获取图片 import requests import re import time import os url = 'https://www.yunxing.club/4380/.html' header = {''} response = requests.get(url, headers=header) dir_name = re.findall('(.*?)', response.text)[0]\t# 文件夹名称 html = response.text urls = re.findall('', html) if not os.path.exists(dir_name): os.mkdir(dir_name) # 创建一个文件夹 for url in urls: time.sleep(0.5) file_name = url.split('/')[-1]\t# 获取图片名称 response1 = requests.get(url, headers=header) with open(dir_name + '/' + file_name, 'wb') as f:\t# 逐个加入文件进入文件夹 f.write(response1.content) 7.try finally : finally在return前执行，在finally的操作，不会改变已经确定的return的值， finally不能加return语句。出现异常，先找是否有处理器可以处理这个异常有处理器可以处理这个异常，再finally。 lxml库\n# etree函数： 1.etree.HTML()接受resquest.text返回的字符串并转换成HTML以便xpath解析 2.etree.parse()接受一个文本路径，可以直接解析【默认解析器是Xpath，可以设置】 3.etree.tostring(文本，encoding='').docode()编码与解码。【用以获取可读的数据】 数据清洗以及自然语言处理\n1.马尔可夫链：# 【实质就是对数据的处理，对字典的灵活运用】 import requests from random import randint def A(wordList): sum = 0 for word, value in wordList.items(): sum += value return sum def B(wordList):\t# 神奇的创造句子的方法。 randIndex = randint(1, A(wordList)) for word, value in wordList.items(): randIndex -= value if randIndex \u003c= 0: # 随机事件，只有数值大的才有可能小于零。 return word def C(text): text = text.replace('\\n', '') text = text.replace('\"', '') punctuation = [',', '.', ';', ':'] for symbol in punctuation: text = text.replace(symbol, '{}'.format(symbol)) words = text.split(' ') words = [word for word in words if word != ''] print(words) wordDict = {} for i in range(1, len(words)): # 蒙逼？ if words[i - 1] not in wordDict: wordDict[words[i - 1]] = {} if words[i] not in wordDict[words[i - 1]]: wordDict[words[i - 1]][words[i]] = 0 wordDict[words[i - 1]][words[i]] += 1 return wordDict text = str(requests.get('http://pythonscraping.com/files/inaugurationSpeech.txt').text) wordDict = C(text) length = 100 chain = ['I'] # 随机输了一个单词。 for i in range(0, length): newWord = B(wordDict[chain[-1]]) chain.append(newWord) print(' '.join(chain)) 2.数据标准化： 3.OpenRefine数据处理应用 NLTK自然语言工具包\n对文本的各种特点进行分析的工具。\npost请求\n1.提交数据时要保证变量名称与数据名称一致。 2.Session()函数可以自动检测cookie,不用时刻跟踪cookie。 import requests session = requests.Session() params = {'username': 'Ryan', 'password': 'password'} r = session.post('https://pythonscraping.com/pages/cookies/welcome.php', params)\t# session函数会自动记录cookie print(r.cookies.get_dict()) a = session.get('http://pythonscraping.com/pages/cookies/profile.php') # 不需要再声明cookie print(a.text) 3.HTTP基本接入认证。 import requests import request.auth import AuthBase\t#这个函数有什么作用？ from requests.auth import HTTPBasicAuth auth = HTTPBasicAuth('ryan', 'password') r = requests.post('https://pythonscraping.com/pages/auth/login.php', auth=auth) print(r.text) ","wordCount":"957","inLanguage":"en","datePublished":"2023-09-24T00:00:00Z","dateModified":"2023-09-24T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"/posts/reptilebase/"},"publisher":{"@type":"Organization","name":"zhang远","logo":{"@type":"ImageObject","url":"favicon.ico"}}}</script>
</head>

<body id=top>
    <script>localStorage.getItem("pref-theme") === "dark" ? document.body.classList.add("dark") : localStorage.getItem("pref-theme") === "light" ? document.body.classList.remove("dark") : window.matchMedia("(prefers-color-scheme: dark)").matches && document.body.classList.add("dark")</script>
    <header class=header>
        <nav class=nav>
            <div class=logo><a href accesskey=h title="zhang远 (Alt + H)">zhang远</a>
                <div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon"
                            xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none"
                            stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z" />
                        </svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18"
                            viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2"
                            stroke-linecap="round" stroke-linejoin="round">
                            <circle cx="12" cy="12" r="5" />
                            <line x1="12" y1="1" x2="12" y2="3" />
                            <line x1="12" y1="21" x2="12" y2="23" />
                            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64" />
                            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78" />
                            <line x1="1" y1="12" x2="3" y2="12" />
                            <line x1="21" y1="12" x2="23" y2="12" />
                            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36" />
                            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22" />
                        </svg></button></div>
            </div>
            <ul id=menu>
                <li><a href=/categories/ title=Categories><span>Categories</span></a></li>
                <li><a href=/tags/ title=Tags><span>Tags</span></a></li>
                <li><a href=/archives/ title=Archives><span>Archives</span></a></li>
            </ul>
        </nav>
    </header>
    <main class=main>
        <article class=post-single>
            <header class=post-header>
                <div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/posts />Posts</a></div>
                <h1 class=post-title>Reptile Learning</h1>
                <div class=post-meta><span title='2023-09-24 00:00:00 +0000 UTC'>September 24,
                        2023</span>&nbsp;·&nbsp;Me</div>
            </header>
            <div class=post-content>
                <p><strong>urllib库（request更方便，在于不用再去构建一个get或者post请求）</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span>urllib库包含以下几个模块<span style=color:#960050;background-color:#1e0010>（</span>模块里面是函数<span style=color:#960050;background-color:#1e0010>）：</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>urllib<span style=color:#f92672>.</span>request <span style=color:#f92672>-</span> 打开和读取 URL<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>urllib<span style=color:#f92672>.</span>error <span style=color:#f92672>-</span> 包含 urllib<span style=color:#f92672>.</span>request 抛出的异常<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>urllib<span style=color:#f92672>.</span>parse <span style=color:#f92672>-</span> 解析 URL<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span><span style=color:#75715e># urllib.robotparser - 解析 robots.txt 文件。</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>拓:
</span></span><span style=display:flex;><span>getcode() 函数获取<span style=color:#e6db74>&#39;网页状态码&#39;</span><span style=color:#960050;background-color:#1e0010>，</span>返回 <span style=color:#ae81ff>200</span> 说明网页正常<span style=color:#960050;background-color:#1e0010>，</span>返回 <span style=color:#ae81ff>404</span> 说明网页不存在
</span></span><span style=display:flex;><span>get_text()获取除标签以外的<span style=color:#e6db74>&#39;文本内容&#39;</span><span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>.</span>attrs获取<span style=color:#e6db74>&#39;标签对象的属性&#39;</span><span style=color:#960050;background-color:#1e0010>，</span>返回一个字典<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>body <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>join([line<span style=color:#f92672>.</span>text <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> lines]) <span style=color:#75715e># 有意思的一种换行循环加入列表。</span>
</span></span><span style=display:flex;><span>title <span style=color:#f92672>=</span> bs<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39;h1&#39;</span>)<span style=color:#f92672>.</span>text  <span style=color:#75715e># text什么意思,去除标签获取文本。</span>
</span></span><span style=display:flex;><span>用类来设置属性<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>zip()函数<span style=color:#960050;background-color:#1e0010>：</span><span style=color:#66d9ef>for</span> i n <span style=color:#f92672>in</span> zip(<span style=color:#f92672>is</span>,ns):[<span style=color:#e6db74>&#39;用以设置一个双循环&#39;</span>]
</span></span><span style=display:flex;><span>str<span style=color:#f92672>.</span>strip([chars]);   参数chars <span style=color:#f92672>--</span> 移除字符串<span style=color:#e6db74>&#39;头尾&#39;</span>指定的字符序列<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>1.</span><span style=color:#e6db74>&#39;urllib.request模块&#39;</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>urllib<span style=color:#f92672>.</span>request<span style=color:#f92672>.</span>urlopen(url, data<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, [timeout, ]<span style=color:#f92672>*</span>, cafile<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, capath<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, cadefault<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, context<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex;><span>url<span style=color:#960050;background-color:#1e0010>：</span>url 地址<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>data<span style=color:#960050;background-color:#1e0010>：</span>发送到服务器的其他数据对象<span style=color:#960050;background-color:#1e0010>，</span>默认为 <span style=color:#66d9ef>None</span><span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>timeout<span style=color:#960050;background-color:#1e0010>：</span>设置访问超时时间<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>cafile 和 capath<span style=color:#960050;background-color:#1e0010>：</span>cafile 为 CA 证书<span style=color:#960050;background-color:#1e0010>，</span> capath 为 CA 证书的路径<span style=color:#960050;background-color:#1e0010>，</span>使用 HTTPS 需要用到<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>cadefault<span style=color:#960050;background-color:#1e0010>：</span>已经被弃用<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>context<span style=color:#960050;background-color:#1e0010>：</span>ssl<span style=color:#f92672>.</span>SSLContext类型<span style=color:#960050;background-color:#1e0010>，</span>用来指定 SSL 设置<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>urllib<span style=color:#f92672>.</span>request<span style=color:#f92672>.</span>Request(url, data<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, headers<span style=color:#f92672>=</span>{}, origin_req_host<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, unverifiable<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, method<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex;><span>url<span style=color:#960050;background-color:#1e0010>：</span>url 地址<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>data<span style=color:#960050;background-color:#1e0010>：</span>发送到服务器的其他数据对象<span style=color:#960050;background-color:#1e0010>，</span>默认为 <span style=color:#66d9ef>None</span><span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span><span style=color:#75715e># headers：HTTP 请求的头部信息，字典格式。</span>
</span></span><span style=display:flex;><span>origin_req_host<span style=color:#960050;background-color:#1e0010>：</span>请求的主机地址<span style=color:#960050;background-color:#1e0010>，</span>IP 或域名<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>unverifiable<span style=color:#960050;background-color:#1e0010>：</span>很少用整个参数<span style=color:#960050;background-color:#1e0010>，</span>用于设置网页是否需要验证<span style=color:#960050;background-color:#1e0010>，</span>默认是Fals                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          e<span style=color:#960050;background-color:#1e0010>。。</span>
</span></span><span style=display:flex;><span><span style=color:#75715e># method：请求方法， 如 GET、POST、DELETE、PUT等。</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span><span style=color:#e6db74>&#39;urllib.error&#39;</span>模块
</span></span><span style=display:flex;><span>urllib<span style=color:#f92672>.</span>error 模块为 urllib<span style=color:#f92672>.</span>request 所引发的异常定义了异常类<span style=color:#960050;background-color:#1e0010>，</span>基础异常类是 URLError<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>urllib<span style=color:#f92672>.</span>error 包含了两个方法<span style=color:#960050;background-color:#1e0010>，</span>URLError 和 HTTPError<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>URLError 是 <span style=color:#a6e22e>OSError</span> 的一个子类<span style=color:#960050;background-color:#1e0010>，</span>用于处理程序在遇到问题时会引发此异常<span style=color:#960050;background-color:#1e0010>（</span>或其派生的异常<span style=color:#960050;background-color:#1e0010>），</span>包含的属性 reason 为引发异常的原因<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>HTTPError 是 URLError 的一个子类<span style=color:#960050;background-color:#1e0010>，</span>用于处理特殊 HTTP 错误例如作为认证请求的时候<span style=color:#960050;background-color:#1e0010>，</span>包含的属性 code 为 HTTP 的状态码<span style=color:#960050;background-color:#1e0010>，</span> reason 为引发异常的原因<span style=color:#960050;background-color:#1e0010>，</span>headers 为导致 HTTPError 的特定 HTTP 请求的 HTTP 响应头
</span></span></code></pre>
                </div>
                <p><strong>BeautifulSoup</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span>bs <span style=color:#f92672>=</span> BeautifulSoup(html<span style=color:#f92672>.</span>read(), <span style=color:#e6db74>&#39;html.parser&#39;</span>)  <span style=color:#75715e># &#39;html.parser是python3中的解析器,lxml解析器需要特定安装,还有html5lib解析器。			&#39;特点就是可以转换成一个对象&#39;</span>
</span></span><span style=display:flex;><span>print(bs<span style=color:#f92672>.</span>body<span style=color:#f92672>.</span>h1) <span style=color:#75715e># 返回一个网页标题。</span>
</span></span></code></pre>
                </div>
                <p><strong>几种异常的获取和分类</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span><span style=color:#ae81ff>1</span><span style=color:#960050;background-color:#1e0010>、</span>网页在服务器上不存在或者获取网页时出现错误<span style=color:#960050;background-color:#1e0010>（</span>HTTP异常<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2</span><span style=color:#960050;background-color:#1e0010>、</span>服务器不存在<span style=color:#960050;background-color:#1e0010>（</span>URL异常<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>AttributeError<span style=color:#960050;background-color:#1e0010>：</span>这个错误就是说python找不到对应的对象的属性<span style=color:#960050;background-color:#1e0010>（</span>一般是没有标签<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> urllib.request <span style=color:#f92672>import</span> urlopen
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> urllib.error <span style=color:#f92672>import</span> URLError
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>gettiller</span>(url):
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex;><span>        html <span style=color:#f92672>=</span> urlopen(url)
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>except</span> URLError:
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>None</span>  <span style=color:#75715e># except执行后就不会执行后面的代码</span>
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex;><span>        bs <span style=color:#f92672>=</span> BeautifulSoup(html<span style=color:#f92672>.</span>read(), <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span><span style=display:flex;><span>        title <span style=color:#f92672>=</span> bs<span style=color:#f92672>.</span>body<span style=color:#f92672>.</span>h1
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>AttributeError</span> <span style=color:#66d9ef>as</span> e:  <span style=color:#75715e># 几种错误的分类。</span>
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>return</span> title
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>title <span style=color:#f92672>=</span> gettiller(<span style=color:#e6db74>&#39;http://www.pythonscraping.com/pages/page1.html&#39;</span>)
</span></span><span style=display:flex;><span><span style=color:#66d9ef>if</span> title <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex;><span>    print(<span style=color:#e6db74>&#39;无法找到页面&#39;</span>)
</span></span><span style=display:flex;><span><span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex;><span>    print(title)
</span></span></code></pre>
                </div>
                <p><strong>HTML解析</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span>Beautifulsoup库里面的四个对象<span style=color:#960050;background-color:#1e0010>：</span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>1.</span>BeautifulSoup对象获取整个文档
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span>标签Tag对象函数find与函数find_all获取
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>NavigableString对象表示标签里面的文字<span style=color:#960050;background-color:#1e0010>。（</span>需要了解函数<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>4.</span>comment对象获取注释<span style=color:#960050;background-color:#1e0010>（</span>需要了解函数<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>标签对象<span style=color:#f92672>.</span>get_text()会清除HTML文档中的所有标签<span style=color:#960050;background-color:#1e0010>，</span>返回字符串
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#75715e># find（）与fand_all（）函数：</span>
</span></span><span style=display:flex;><span>find(标签<span style=color:#960050;background-color:#1e0010>，</span>标签属性<span style=color:#960050;background-color:#1e0010>（</span>{class:<span style=color:#e6db74>&#39;&#39;</span>})<span style=color:#960050;background-color:#1e0010>，</span>递归布尔变量<span style=color:#960050;background-color:#1e0010>，</span>text<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;匹配文本内容&#39;</span><span style=color:#960050;background-color:#1e0010>，</span>keuwords关键字参数<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span>find_all() 
</span></span><span style=display:flex;><span>[关键字keywords:<span style=color:#e6db74>&#39;id是一种HTML属性&#39;</span><span style=color:#960050;background-color:#1e0010>（</span>都可以直接用claas的字典属性获取<span style=color:#960050;background-color:#1e0010>），</span>class_<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;green&#39;</span>直接获取具有green颜色属性的标签]
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>导航树<span style=color:#960050;background-color:#1e0010>：</span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>1.</span>子标签和父标签以及后代标签<span style=color:#960050;background-color:#1e0010>（</span>区别<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>.</span>descendants后代标签
</span></span><span style=display:flex;><span><span style=color:#f92672>.</span>children子标签
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span>处理兄弟标签
</span></span><span style=display:flex;><span><span style=color:#f92672>.</span>next_siblings获取所有<span style=color:#e6db74>&#39;兄弟标签&#39;</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>.</span>previous_siblings当你知道兄弟标签的最后一个标签后可获取前面的<span style=color:#e6db74>&#39;所有标签&#39;</span><span style=color:#960050;background-color:#1e0010>（</span>当然得是复数形式<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>处理父标签
</span></span><span style=display:flex;><span><span style=color:#f92672>.</span>parent
</span></span><span style=display:flex;><span><span style=color:#f92672>.</span>parents
</span></span><span style=display:flex;><span>例子<span style=color:#960050;background-color:#1e0010>：</span>print(bs<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39;img&#39;</span>, {<span style=color:#e6db74>&#39;src&#39;</span>: <span style=color:#e6db74>&#39;../img/gifts/img1.jpg&#39;</span>})<span style=color:#f92672>.</span>parent<span style=color:#f92672>.</span>previous_sibling<span style=color:#f92672>.</span>get_text())
</span></span><span style=display:flex;><span><span style=color:#ae81ff>4.</span>正则表达式和BeautifulSoup
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> urllib.request <span style=color:#f92672>import</span> urlopen
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex;><span>html <span style=color:#f92672>=</span> urlopen(<span style=color:#e6db74>&#39;https://www.pythonscraping.com/pages/page3.html&#39;</span>)
</span></span><span style=display:flex;><span>bs <span style=color:#f92672>=</span> BeautifulSoup(html<span style=color:#f92672>.</span>read(), <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span><span style=display:flex;><span>images <span style=color:#f92672>=</span> bs<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;img&#39;</span>, dict(src<span style=color:#f92672>=</span>re<span style=color:#f92672>.</span>compile(<span style=color:#e6db74>&#39;\.\./img/gifts/img.*\.jpg&#39;</span>)))
</span></span><span style=display:flex;><span><span style=color:#66d9ef>for</span> image <span style=color:#f92672>in</span> images:
</span></span><span style=display:flex;><span>    print(image<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;src&#39;</span>])  <span style=color:#75715e># 可以获取图片的地址。</span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>5.</span>Lambda表达式
</span></span><span style=display:flex;><span><span style=color:#75715e>#不太会</span>
</span></span></code></pre>
                </div>
                <p><strong>编写网络爬虫</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span><span style=color:#ae81ff>1.</span>网页跳转<span style=color:#960050;background-color:#1e0010>（</span><span style=color:#e6db74>&#39;急需改进&#39;</span><span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> urllib.request <span style=color:#f92672>import</span> urlopen
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex;><span>random<span style=color:#f92672>.</span>seed(datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now())  <span style=color:#75715e># 随机数</span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>getLinks</span>(art):
</span></span><span style=display:flex;><span>    html <span style=color:#f92672>=</span> urlopen(<span style=color:#e6db74>&#39;https://en.wikipedia.beta.wmflabs.org</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(art))
</span></span><span style=display:flex;><span>    bs <span style=color:#f92672>=</span> BeautifulSoup(html, <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>return</span> bs<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39;div&#39;</span>, {<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#e6db74>&#39;mw-content-text&#39;</span>})<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;a&#39;</span>, {<span style=color:#e6db74>&#39;class&#39;</span>: <span style=color:#e6db74>&#39;new&#39;</span>}) <span style=color:#75715e># 不可以用class，太死板。</span>
</span></span><span style=display:flex;><span>links <span style=color:#f92672>=</span> getLinks(<span style=color:#e6db74>&#39;/wiki/Kyberpunk&#39;</span>)
</span></span><span style=display:flex;><span><span style=color:#66d9ef>while</span> len(links) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex;><span>    newArticle <span style=color:#f92672>=</span> links[random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>0</span>, len(links) <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>)]<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>]
</span></span><span style=display:flex;><span>    print(newArticle)
</span></span><span style=display:flex;><span>    links <span style=color:#f92672>=</span> getLinks(newArticle)
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span>随机数种子
</span></span><span style=display:flex;><span>random<span style=color:#f92672>.</span>seed(datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()) <span style=color:#75715e># 不知道何用？</span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>爬取网站(<span style=color:#e6db74>&#39;还是不知道错在哪？&#39;</span>)
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> urllib.request <span style=color:#f92672>import</span> urlopen
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex;><span>page <span style=color:#f92672>=</span> set()
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>getLinks</span>(art):
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>global</span> page
</span></span><span style=display:flex;><span>    html <span style=color:#f92672>=</span> urlopen(<span style=color:#e6db74>&#39;https://en.wikipedia.beta.wmflabs.org</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(art))
</span></span><span style=display:flex;><span>    bs <span style=color:#f92672>=</span> BeautifulSoup(html<span style=color:#f92672>.</span>read(), <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>for</span> link <span style=color:#f92672>in</span> bs<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;a&#39;</span>, href<span style=color:#f92672>=</span>re<span style=color:#f92672>.</span>compile(<span style=color:#e6db74>&#39;^(/wiki/)&#39;</span>)):
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;href&#39;</span> <span style=color:#f92672>in</span> link<span style=color:#f92672>.</span>attrs:
</span></span><span style=display:flex;><span>            <span style=color:#66d9ef>if</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>] <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> page:
</span></span><span style=display:flex;><span>                newPage <span style=color:#f92672>=</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>]
</span></span><span style=display:flex;><span>                print(newPage)
</span></span><span style=display:flex;><span>                page<span style=color:#f92672>.</span>add(newPage)
</span></span><span style=display:flex;><span>                getLinks(newPage) 
</span></span><span style=display:flex;><span>getLinks(<span style=color:#e6db74>&#39;&#39;</span>)
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>请求头的设置
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> urllib.request <span style=color:#e6db74>&#39;要先导入urllib.request模块&#39;</span>
</span></span><span style=display:flex;><span>header <span style=color:#f92672>=</span> {
</span></span><span style=display:flex;><span>        <span style=color:#e6db74>&#39;user-agent&#39;</span>: <span style=color:#e6db74>&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36 Edg/96.0.1054.62&#39;</span>}
</span></span><span style=display:flex;><span> resquest <span style=color:#f92672>=</span> urllib<span style=color:#f92672>.</span>request<span style=color:#f92672>.</span>Request(<span style=color:#e6db74>&#39;https://en.wikipedia.beta.wmflabs.org&#39;</span> ,headers<span style=color:#f92672>=</span>header)
</span></span><span style=display:flex;><span> html <span style=color:#f92672>=</span> urlopen(resquest)
</span></span><span style=display:flex;><span> bs <span style=color:#f92672>=</span> BeautifulSoup(html<span style=color:#f92672>.</span>read(), <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span></code></pre>
                </div>
                <p><strong>收集网站数据</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span><span style=color:#ae81ff>1.</span><span style=color:#f92672>from</span> urllib.request <span style=color:#f92672>import</span> urlopen
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex;><span>pages <span style=color:#f92672>=</span> set()
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>getLink</span>(art):
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>global</span> pages
</span></span><span style=display:flex;><span>    html <span style=color:#f92672>=</span> urlopen(<span style=color:#e6db74>&#39;https://en.wikipedia.beta.wmflabs.org</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(art))
</span></span><span style=display:flex;><span>    bs <span style=color:#f92672>=</span> BeautifulSoup(html<span style=color:#f92672>.</span>read(), <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex;><span>        print(bs<span style=color:#f92672>.</span>h1<span style=color:#f92672>.</span>get_text())		<span style=color:#75715e># 这种多行检测容易失去一些数据。 </span>
</span></span><span style=display:flex;><span>        print(bs<span style=color:#f92672>.</span>find(id<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mw-content-text&#39;</span>)<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;p&#39;</span>))
</span></span><span style=display:flex;><span>        print(bs<span style=color:#f92672>.</span>find(id<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ca-edit&#39;</span>)<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39;span&#39;</span>)<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39;a&#39;</span>)<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>])
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>AttributeError</span>:	<span style=color:#75715e># 即使报错也也会进行下一步。</span>
</span></span><span style=display:flex;><span>        print(<span style=color:#e6db74>&#39;页面缺少了一些属性.&#39;</span>)
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>for</span> link <span style=color:#f92672>in</span> bs<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;a&#39;</span>, href<span style=color:#f92672>=</span>re<span style=color:#f92672>.</span>compile(<span style=color:#e6db74>&#39;^(/wiki/)&#39;</span>)):
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;href&#39;</span> <span style=color:#f92672>in</span> link<span style=color:#f92672>.</span>attrs:
</span></span><span style=display:flex;><span>            <span style=color:#66d9ef>if</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>] <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> pages:
</span></span><span style=display:flex;><span>                newpPage <span style=color:#f92672>=</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>]
</span></span><span style=display:flex;><span>                print(<span style=color:#e6db74>&#39;-&#39;</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>20</span>)
</span></span><span style=display:flex;><span>                print(newpPage)
</span></span><span style=display:flex;><span>                pages<span style=color:#f92672>.</span>add(newpPage)
</span></span><span style=display:flex;><span>                getLink(newpPage)
</span></span><span style=display:flex;><span>getLink(<span style=color:#e6db74>&#39;&#39;</span>)
</span></span><span style=display:flex;><span>难点<span style=color:#960050;background-color:#1e0010>：</span>各种标签的规律<span style=color:#960050;background-color:#1e0010>（</span>花时间去了解一下标签的的东西<span style=color:#960050;background-color:#1e0010>）。</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span><span style=color:#e6db74>&#39;startswith()&#39;</span>方法用于检查字符串是否是以指定子字符串开头<span style=color:#960050;background-color:#1e0010>，</span>如果是则返回 <span style=color:#66d9ef>True</span><span style=color:#960050;background-color:#1e0010>，</span>否则返回 <span style=color:#66d9ef>False</span><span style=color:#960050;background-color:#1e0010>。</span>如果参数 beg 和 end 指定值<span style=color:#960050;background-color:#1e0010>，</span>则在指定范围内检查<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>语法
</span></span><span style=display:flex;><span>startswith()方法语法<span style=color:#960050;background-color:#1e0010>：</span>
</span></span><span style=display:flex;><span>str<span style=color:#f92672>.</span>startswith(str, beg<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,end<span style=color:#f92672>=</span>len(string));
</span></span><span style=display:flex;><span>参数
</span></span><span style=display:flex;><span>str <span style=color:#f92672>--</span> 检测的字符串<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>strbeg <span style=color:#f92672>--</span> 可选参数用于设置字符串检测的起始位置<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>strend <span style=color:#f92672>--</span> 可选参数用于设置字符串检测的结束位置<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>返回值
</span></span><span style=display:flex;><span>如果检测到字符串则返回True<span style=color:#960050;background-color:#1e0010>，</span>否则返回False<span style=color:#960050;background-color:#1e0010>。</span>
</span></span></code></pre>
                </div>
                <p><strong>在互联网上抓取</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span><span style=color:#f92672>from</span> urllib.request <span style=color:#f92672>import</span> urlopen
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> urllib.parse <span style=color:#f92672>import</span> urlparse	<span style=color:#75715e># 用于解析</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>pages <span style=color:#f92672>=</span> set()
</span></span><span style=display:flex;><span>random<span style=color:#f92672>.</span>seed(datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now())
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>getInUrl</span>(bs, includeUrl): <span style=color:#75715e># 搜集内链</span>
</span></span><span style=display:flex;><span>    includeUrl <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>://</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(urlparse(includeUrl)<span style=color:#f92672>.</span>scheme, urlparse(includeUrl)<span style=color:#f92672>.</span>netloc)
</span></span><span style=display:flex;><span>    inLinks <span style=color:#f92672>=</span> []
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>for</span> link <span style=color:#f92672>in</span> bs<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;a&#39;</span>, href<span style=color:#f92672>=</span>re<span style=color:#f92672>.</span>compile(<span style=color:#e6db74>&#39;^(/|.*&#39;</span> <span style=color:#f92672>+</span> includeUrl <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;)&#39;</span>)):
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>if</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>] <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex;><span>            <span style=color:#66d9ef>if</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>] <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> inLinks:
</span></span><span style=display:flex;><span>                <span style=color:#66d9ef>if</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>]<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#39;/&#39;</span>):
</span></span><span style=display:flex;><span>                    inLinks<span style=color:#f92672>.</span>append(includeUrl <span style=color:#f92672>+</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>])
</span></span><span style=display:flex;><span>                <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex;><span>                    inLinks<span style=color:#f92672>.</span>append(link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>])
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>return</span> inLinks
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>getExitUrl</span>(bs, exUrl):	<span style=color:#75715e># 搜集外链</span>
</span></span><span style=display:flex;><span>    exLinks <span style=color:#f92672>=</span> []
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>for</span> link <span style=color:#f92672>in</span> bs<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;a&#39;</span>, href<span style=color:#f92672>=</span>re<span style=color:#f92672>.</span>compile(<span style=color:#e6db74>&#39;^(http|www)((?!&#39;</span> <span style=color:#f92672>+</span> exUrl <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;).)*$&#39;</span>)):  <span style=color:#75715e># 正则表达式。</span>
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>if</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>] <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex;><span>            <span style=color:#66d9ef>if</span> link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>] <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> exLinks:
</span></span><span style=display:flex;><span>                exLinks<span style=color:#f92672>.</span>append(link<span style=color:#f92672>.</span>attrs[<span style=color:#e6db74>&#39;href&#39;</span>])
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>return</span> exLinks
</span></span><span style=display:flex;><span>    
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>getRandomExternalLinks</span>(startingPage):  <span style=color:#75715e># 随机获取外部链接。（开始页面)</span>
</span></span><span style=display:flex;><span>    html <span style=color:#f92672>=</span> urlopen(startingPage)
</span></span><span style=display:flex;><span>    bs <span style=color:#f92672>=</span> BeautifulSoup(html<span style=color:#f92672>.</span>read(), <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span><span style=display:flex;><span>    exLinks <span style=color:#f92672>=</span> getExitUrl(bs, urlparse(startingPage)<span style=color:#f92672>.</span>netloc)  <span style=color:#75715e># 获取域名,获取外链。</span>
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>if</span> len(exLinks) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex;><span>        print(<span style=color:#e6db74>&#39;不存在外部链接（一般不可能)&#39;</span>)
</span></span><span style=display:flex;><span>        domain <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>://</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(urlparse(startingPage)<span style=color:#f92672>.</span>scheme, urlparse(startingPage)<span style=color:#f92672>.</span>netloc)
</span></span><span style=display:flex;><span>        internalLink <span style=color:#f92672>=</span> getInUrl(bs, domain)  <span style=color:#75715e># 就去寻求另一个内链。</span>
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>return</span> getRandomExternalLinks(internalLink[random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>0</span>, len(internalLink) <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>)])
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>return</span> exLinks[random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>0</span>, len(exLinks))]  <span style=color:#75715e># 随机返回一个外链</span>
</span></span><span style=display:flex;><span>        
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>followExternalOnly</span>(startingSite):	<span style=color:#75715e># 实现网站跳转。</span>
</span></span><span style=display:flex;><span>    exLink <span style=color:#f92672>=</span> getRandomExternalLinks(startingSite)
</span></span><span style=display:flex;><span>    print(<span style=color:#e6db74>&#39;随机获取的外部链接是</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(exLink))
</span></span><span style=display:flex;><span>    followExternalOnly(exLink)
</span></span><span style=display:flex;><span>followExternalOnly(<span style=color:#e6db74>&#39;http://oreilly.com&#39;</span>)
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>1.</span><span style=color:#e6db74>&#39;urlparse()&#39;</span>函数可以将 URL 解析成 ParseResult对象<span style=color:#960050;background-color:#1e0010>。</span>对象中包含了六个元素<span style=color:#960050;background-color:#1e0010>，</span>分别为<span style=color:#960050;background-color:#1e0010>：</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> urllib.parse <span style=color:#f92672>import</span> urlparse
</span></span><span style=display:flex;><span>协议<span style=color:#960050;background-color:#1e0010>（</span><span style=color:#f92672>.</span>scheme<span style=color:#960050;background-color:#1e0010>）</span> 
</span></span><span style=display:flex;><span>域名<span style=color:#960050;background-color:#1e0010>（</span><span style=color:#f92672>.</span>netloc<span style=color:#960050;background-color:#1e0010>）</span> 
</span></span><span style=display:flex;><span>路径<span style=color:#960050;background-color:#1e0010>（</span><span style=color:#f92672>.</span>path<span style=color:#960050;background-color:#1e0010>）</span> 
</span></span><span style=display:flex;><span>路径参数<span style=color:#960050;background-color:#1e0010>（</span><span style=color:#f92672>.</span>params<span style=color:#960050;background-color:#1e0010>）</span> 
</span></span><span style=display:flex;><span>查询参数<span style=color:#960050;background-color:#1e0010>（</span><span style=color:#f92672>.</span>query<span style=color:#960050;background-color:#1e0010>）</span> 
</span></span><span style=display:flex;><span>片段<span style=color:#960050;background-color:#1e0010>（</span><span style=color:#f92672>.</span>fragment<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span><span style=color:#e6db74>&#39;select()&#39;</span>函数[相当于fand_all的用法]
</span></span><span style=display:flex;><span>我们在写 CSS 时<span style=color:#960050;background-color:#1e0010>，</span>标签名不加任何修饰<span style=color:#960050;background-color:#1e0010>，</span>类名<span style=color:#960050;background-color:#1e0010>（</span>class<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;className&#34;</span>引号内即为类名<span style=color:#960050;background-color:#1e0010>）</span>前加点<span style=color:#960050;background-color:#1e0010>，</span>id名<span style=color:#960050;background-color:#1e0010>（</span>id<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;idName&#34;</span>引号前即为id名<span style=color:#960050;background-color:#1e0010>）</span>前加 <span style=color:#75715e>#，在这里我们也可以利用类似的方法来筛选元素，用到的方法是 bs.select()，返回类型是 list</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>以下是request<span style=color:#f92672>.</span>exceptions下的各种异常错误<span style=color:#960050;background-color:#1e0010>：</span>
</span></span><span style=display:flex;><span><span style=color:#e6db74>&#39;RequestException&#39;</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>4.</span>Python replace() 方法用于把字符串中的 old<span style=color:#960050;background-color:#1e0010>（</span>旧字符串<span style=color:#960050;background-color:#1e0010>）</span> 替换成 new(新字符串)<span style=color:#960050;background-color:#1e0010>，</span>如果指定第三个参数max<span style=color:#960050;background-color:#1e0010>，</span>则替换不超过 max 次<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>语法<span style=color:#960050;background-color:#1e0010>：</span>
</span></span><span style=display:flex;><span>str<span style=color:#f92672>.</span>replace(old, new[, max])
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>5.</span>os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>exists()就是判断括号里的文件是否存在的意思<span style=color:#960050;background-color:#1e0010>【</span>返回布尔值<span style=color:#960050;background-color:#1e0010>】</span>
</span></span><span style=display:flex;><span>os<span style=color:#f92672>.</span>makedirs递归创建目录<span style=color:#960050;background-color:#1e0010>（</span>无返回值<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>6.</span>获取图片
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> requests
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex;><span>url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;https://www.yunxing.club/4380/.html&#39;</span>
</span></span><span style=display:flex;><span>header <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;&#39;</span>}
</span></span><span style=display:flex;><span>response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(url, headers<span style=color:#f92672>=</span>header)
</span></span><span style=display:flex;><span>dir_name <span style=color:#f92672>=</span> re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>&#39;&lt;h1 class=&#34;article-title&#34;&gt;(.*?)&lt;/h1&gt;&#39;</span>, response<span style=color:#f92672>.</span>text)[<span style=color:#ae81ff>0</span>]	<span style=color:#75715e># 文件夹名称</span>
</span></span><span style=display:flex;><span>html <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>text
</span></span><span style=display:flex;><span>urls <span style=color:#f92672>=</span> re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>&#39;&lt;img loading=&#34;.*?&#34; src=&#34;(.*?)&#34; alt=&#34;&#34; class=&#34;.*?&#34; width=&#34;.*?&#34; height=&#34;.*?&#34; srcset=&#34;.*?&#34; /&gt;&#39;</span>, html)
</span></span><span style=display:flex;><span><span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>exists(dir_name):
</span></span><span style=display:flex;><span>    os<span style=color:#f92672>.</span>mkdir(dir_name) <span style=color:#75715e># 创建一个文件夹</span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>for</span> url <span style=color:#f92672>in</span> urls:
</span></span><span style=display:flex;><span>    time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>0.5</span>)
</span></span><span style=display:flex;><span>    file_name <span style=color:#f92672>=</span> url<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;/&#39;</span>)[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]	<span style=color:#75715e># 获取图片名称</span>
</span></span><span style=display:flex;><span>    response1 <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(url, headers<span style=color:#f92672>=</span>header)
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>with</span> open(dir_name <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;/&#39;</span> <span style=color:#f92672>+</span> file_name, <span style=color:#e6db74>&#39;wb&#39;</span>) <span style=color:#66d9ef>as</span> f:	<span style=color:#75715e># 逐个加入文件进入文件夹</span>
</span></span><span style=display:flex;><span>        f<span style=color:#f92672>.</span>write(response1<span style=color:#f92672>.</span>content)
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>7.</span><span style=color:#66d9ef>try</span>  <span style=color:#66d9ef>finally</span> :
</span></span><span style=display:flex;><span>finally在return前执行<span style=color:#960050;background-color:#1e0010>，</span>在finally的操作<span style=color:#960050;background-color:#1e0010>，</span>不会改变已经确定的return的值<span style=color:#960050;background-color:#1e0010>，</span> finally不能加return语句<span style=color:#960050;background-color:#1e0010>。</span>出现异常<span style=color:#960050;background-color:#1e0010>，</span>先找是否有处理器可以处理这个异常有处理器可以处理这个异常<span style=color:#960050;background-color:#1e0010>，</span>再finally<span style=color:#960050;background-color:#1e0010>。</span> 
</span></span></code></pre>
                </div>
                <p><strong>lxml库</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span><span style=color:#75715e># etree函数：</span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>1.</span>etree<span style=color:#f92672>.</span>HTML()接受resquest<span style=color:#f92672>.</span>text返回的字符串并转换成HTML以便xpath解析
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span>etree<span style=color:#f92672>.</span>parse()接受一个文本路径<span style=color:#960050;background-color:#1e0010>，</span>可以直接解析<span style=color:#960050;background-color:#1e0010>【</span>默认解析器是Xpath<span style=color:#960050;background-color:#1e0010>，</span>可以设置<span style=color:#960050;background-color:#1e0010>】</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>etree<span style=color:#f92672>.</span>tostring(文本<span style=color:#960050;background-color:#1e0010>，</span>encoding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#39;</span>)<span style=color:#f92672>.</span>docode()编码与解码<span style=color:#960050;background-color:#1e0010>。【</span>用以获取可读的数据<span style=color:#960050;background-color:#1e0010>】</span>
</span></span></code></pre>
                </div>
                <p><strong>数据清洗以及自然语言处理</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span><span style=color:#ae81ff>1.</span>马尔可夫链<span style=color:#960050;background-color:#1e0010>：</span><span style=color:#75715e># 【实质就是对数据的处理，对字典的灵活运用】</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> requests
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> random <span style=color:#f92672>import</span> randint
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>A</span>(wordList):
</span></span><span style=display:flex;><span>    sum <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>for</span> word, value <span style=color:#f92672>in</span> wordList<span style=color:#f92672>.</span>items(): 
</span></span><span style=display:flex;><span>        sum <span style=color:#f92672>+=</span> value
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>return</span> sum
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>B</span>(wordList):	<span style=color:#75715e># 神奇的创造句子的方法。</span>
</span></span><span style=display:flex;><span>    randIndex <span style=color:#f92672>=</span> randint(<span style=color:#ae81ff>1</span>, A(wordList))
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>for</span> word, value <span style=color:#f92672>in</span> wordList<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex;><span>        randIndex <span style=color:#f92672>-=</span> value
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>if</span> randIndex <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>0</span>:  <span style=color:#75715e># 随机事件，只有数值大的才有可能小于零。</span>
</span></span><span style=display:flex;><span>            <span style=color:#66d9ef>return</span> word
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>C</span>(text):
</span></span><span style=display:flex;><span>    text <span style=color:#f92672>=</span> text<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span>, <span style=color:#e6db74>&#39;&#39;</span>)
</span></span><span style=display:flex;><span>    text <span style=color:#f92672>=</span> text<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;&#34;&#39;</span>, <span style=color:#e6db74>&#39;&#39;</span>)
</span></span><span style=display:flex;><span>    punctuation <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;,&#39;</span>, <span style=color:#e6db74>&#39;.&#39;</span>, <span style=color:#e6db74>&#39;;&#39;</span>, <span style=color:#e6db74>&#39;:&#39;</span>]
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>for</span> symbol <span style=color:#f92672>in</span> punctuation:
</span></span><span style=display:flex;><span>        text <span style=color:#f92672>=</span> text<span style=color:#f92672>.</span>replace(symbol, <span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(symbol))
</span></span><span style=display:flex;><span>    words <span style=color:#f92672>=</span> text<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39; &#39;</span>)
</span></span><span style=display:flex;><span>    words <span style=color:#f92672>=</span> [word <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> words <span style=color:#66d9ef>if</span> word <span style=color:#f92672>!=</span> <span style=color:#e6db74>&#39;&#39;</span>]
</span></span><span style=display:flex;><span>    print(words)
</span></span><span style=display:flex;><span>    wordDict <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>, len(words)):  <span style=color:#75715e># 蒙逼？</span>
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>if</span> words[i <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>] <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> wordDict:
</span></span><span style=display:flex;><span>            wordDict[words[i <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>]] <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex;><span>        <span style=color:#66d9ef>if</span> words[i] <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> wordDict[words[i <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>]]:
</span></span><span style=display:flex;><span>            wordDict[words[i <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>]][words[i]] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex;><span>        wordDict[words[i <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>]][words[i]] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex;><span>    <span style=color:#66d9ef>return</span> wordDict
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>text <span style=color:#f92672>=</span> str(requests<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;http://pythonscraping.com/files/inaugurationSpeech.txt&#39;</span>)<span style=color:#f92672>.</span>text)
</span></span><span style=display:flex;><span>wordDict <span style=color:#f92672>=</span> C(text)
</span></span><span style=display:flex;><span>length <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex;><span>chain <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;I&#39;</span>]  <span style=color:#75715e># 随机输了一个单词。</span>
</span></span><span style=display:flex;><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, length):
</span></span><span style=display:flex;><span>    newWord <span style=color:#f92672>=</span> B(wordDict[chain[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]]) 
</span></span><span style=display:flex;><span>    chain<span style=color:#f92672>.</span>append(newWord)
</span></span><span style=display:flex;><span>print(<span style=color:#e6db74>&#39; &#39;</span><span style=color:#f92672>.</span>join(chain))
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span>数据标准化<span style=color:#960050;background-color:#1e0010>：</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>OpenRefine数据处理应用
</span></span></code></pre>
                </div>
                <p><strong>NLTK自然语言工具包</strong></p>
                <p>对文本的各种特点进行分析的工具。</p>
                <p><strong>post请求</strong></p>
                <div class=highlight>
                    <pre tabindex=0
                        style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;><code class=language-python data-lang=python><span style=display:flex;><span><span style=color:#ae81ff>1.</span>提交数据时要保证变量名称与数据名称一致<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>2.</span>Session()函数可以自动检测cookie,不用时刻跟踪cookie<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> requests
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>session <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>Session()
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>params <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;username&#39;</span>: <span style=color:#e6db74>&#39;Ryan&#39;</span>, <span style=color:#e6db74>&#39;password&#39;</span>: <span style=color:#e6db74>&#39;password&#39;</span>}
</span></span><span style=display:flex;><span>r <span style=color:#f92672>=</span> session<span style=color:#f92672>.</span>post(<span style=color:#e6db74>&#39;https://pythonscraping.com/pages/cookies/welcome.php&#39;</span>, params)	<span style=color:#75715e># session函数会自动记录cookie</span>
</span></span><span style=display:flex;><span>print(r<span style=color:#f92672>.</span>cookies<span style=color:#f92672>.</span>get_dict())
</span></span><span style=display:flex;><span>a <span style=color:#f92672>=</span> session<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;http://pythonscraping.com/pages/cookies/profile.php&#39;</span>)  <span style=color:#75715e># 不需要再声明cookie</span>
</span></span><span style=display:flex;><span>print(a<span style=color:#f92672>.</span>text)
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span><span style=color:#ae81ff>3.</span>HTTP基本接入认证<span style=color:#960050;background-color:#1e0010>。</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> requests
</span></span><span style=display:flex;><span><span style=color:#f92672>import</span> request.auth <span style=color:#f92672>import</span> AuthBase	   <span style=color:#75715e>#这个函数有什么作用？</span>
</span></span><span style=display:flex;><span><span style=color:#f92672>from</span> requests.auth <span style=color:#f92672>import</span> HTTPBasicAuth
</span></span><span style=display:flex;><span>
</span></span><span style=display:flex;><span>auth <span style=color:#f92672>=</span> HTTPBasicAuth(<span style=color:#e6db74>&#39;ryan&#39;</span>, <span style=color:#e6db74>&#39;password&#39;</span>)
</span></span><span style=display:flex;><span>r <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>post(<span style=color:#e6db74>&#39;https://pythonscraping.com/pages/auth/login.php&#39;</span>, auth<span style=color:#f92672>=</span>auth)
</span></span><span style=display:flex;><span>print(r<span style=color:#f92672>.</span>text)
</span></span></code></pre>
                </div>
            </div>
            <footer class=post-footer>
                <ul class=post-tags>
                    <li><a href=/tags/python />python</a></li>
                </ul>
                <nav class=paginav><a class=prev href=/posts/javabase /><span class=title>« Prev</span><br><span>java
                        Base</span></a>
                    <a class=next href=/posts/imagesent /><span class=title>Next »</span><br><span>Use Django to store
                        images sent from the front end</span></a>
                </nav>
            </footer>
        </article>
    </main>
    <footer class=footer><span>&copy; 2023 <a href>zhang远</a></span>
        <span>Powered by
            <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
            <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span>
    </footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg
            xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor">
            <path d="M12 6H0l6-6z" />
        </svg></a>
    <script>let menu = document.getElementById("menu"); menu && (menu.scrollLeft = localStorage.getItem("menu-scroll-position"), menu.onscroll = function () { localStorage.setItem("menu-scroll-position", menu.scrollLeft) }), document.querySelectorAll('a[href^="#"]').forEach(e => { e.addEventListener("click", function (e) { e.preventDefault(); var t = this.getAttribute("href").substr(1); window.matchMedia("(prefers-reduced-motion: reduce)").matches ? document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView() : document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({ behavior: "smooth" }), t === "top" ? history.replaceState(null, null, " ") : history.pushState(null, null, `#${t}`) }) })</script>
    <script>var mybutton = document.getElementById("top-link"); window.onscroll = function () { document.body.scrollTop > 800 || document.documentElement.scrollTop > 800 ? (mybutton.style.visibility = "visible", mybutton.style.opacity = "1") : (mybutton.style.visibility = "hidden", mybutton.style.opacity = "0") }</script>
    <script>document.getElementById("theme-toggle").addEventListener("click", () => { document.body.className.includes("dark") ? (document.body.classList.remove("dark"), localStorage.setItem("pref-theme", "light")) : (document.body.classList.add("dark"), localStorage.setItem("pref-theme", "dark")) })</script>
</body>

</html>